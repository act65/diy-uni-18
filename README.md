
Self-taught course in data science and related math.

## Semester 1

#### Math 441: (Online and convex?) optimisation

Online optimisation, aka memory limited optimisation?

Would be cool to search for bounds/fastest descent possible.

Readings

* Mirror descent
* Time and memory complexity
* EWA
* ?

Projects

* Implement streaming PCA
* Case study on ADAM
* Local gradient statistics
* Higher order gradients

#### Data science 452: Credit assignment

* Why do we want gradients/why do we care?
* What problem does AD solve? 

Readings

* Efficiency
* Functional and categorical AD
* [Long-term dependencies](Bengio)
* Alternative credit assignment -- ???

Projects

* Implement double recursive AD
* Implement efficient graph based reverse AD
* Explore a pathological setting where long-term dependencies make learning 'hard'
* Synthetic gradients

## Semester 2

#### Eng 377: (Graph) signal processing

* Sparse representations: The fourier transformation
* The laplacian
* Graph embeddings for ML

#### Stats 323: (Statistical) learning theory

* Sample complexity  
* Assumptions about the data (IID, noise, ...)
* Complexity measures and bounding generalisation

## Semester 3

#### Math 447: Tensor networks

* Contractions, GEMM and Strassen's algorithm
* Case study: Singular value decomposition(s) - HOSVD, HSVD
* Complex tensor networks

#### Data science 453: Learning discrete models

* Combinatorial optimisation
* Gradient estimation through non-differentiable operations and various data structures
* Learning discretised networks (ES, distillation, quantisation, ...?)

## Project

> Automated science and math.

Math and science have become too big for individuals. We find it hard to keep up and to cram the relevant knowledge into our small heads. We need better tools to continue push the boundaries.

## Dates

* Semester 1: March 5th - June 8th
* Semester 2: July 2nd - October 12th
* Semester 3: November 5th - Feburary 22nd
